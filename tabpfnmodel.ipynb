{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":72489,"databundleVersionId":8096274,"sourceType":"competition"}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm, trange\nimport optuna\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import StepLR\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import MinMaxScaler, LabelEncoder\nfrom sklearn.model_selection import KFold\n\nimport optuna\nfrom optuna.samplers import TPESampler","metadata":{"execution":{"iopub.status.busy":"2024-04-20T15:05:23.108098Z","iopub.execute_input":"2024-04-20T15:05:23.108455Z","iopub.status.idle":"2024-04-20T15:05:29.072026Z","shell.execute_reply.started":"2024-04-20T15:05:23.108414Z","shell.execute_reply":"2024-04-20T15:05:29.071105Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/playground-series-s4e4/train.csv')\ntest = pd.read_csv('/kaggle/input/playground-series-s4e4/test.csv')\ntrain.drop(columns=['id'], axis=1, inplace=True)\ntest.drop(columns=['id'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-20T15:05:38.226265Z","iopub.execute_input":"2024-04-20T15:05:38.226819Z","iopub.status.idle":"2024-04-20T15:05:38.524981Z","shell.execute_reply.started":"2024-04-20T15:05:38.226784Z","shell.execute_reply":"2024-04-20T15:05:38.524117Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"encoder = LabelEncoder()\nscaler = MinMaxScaler()\n\ntrain['Sex'] = encoder.fit_transform(train['Sex'])\ntest['Sex'] = encoder.transform(test['Sex'])\n\ncat_cols = ['Sex']\ntarget = 'Rings'\ncontinuous_cols = [col for col in train.columns if col not in cat_cols + [target]]\n\ntrain[continuous_cols] = scaler.fit_transform(train[continuous_cols])\ntest[continuous_cols] = scaler.transform(test[continuous_cols])\n\nX = train.drop(columns=['Rings'], axis=1).values\ny = train['Rings'].values\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.27, random_state=24)\nX_train_tensor = torch.tensor(X_train, dtype=torch.float32)\nX_val_tensor = torch.tensor(X_val, dtype=torch.float32)\ny_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\ny_val_tensor = torch.tensor(y_val, dtype=torch.float32).view(-1, 1)\n\n# Create TensorDataset instances for training and validation\ntrain_dataset = TensorDataset(X_train_tensor, y_train_tensor)\nval_dataset = TensorDataset(X_val_tensor, y_val_tensor)\nbatch_size = 122\n# Create DataLoader instances for training and validation\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-04-20T15:05:40.006320Z","iopub.execute_input":"2024-04-20T15:05:40.006689Z","iopub.status.idle":"2024-04-20T15:05:40.129345Z","shell.execute_reply.started":"2024-04-20T15:05:40.006662Z","shell.execute_reply":"2024-04-20T15:05:40.128500Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-04-20T15:05:42.975966Z","iopub.execute_input":"2024-04-20T15:05:42.976381Z","iopub.status.idle":"2024-04-20T15:05:42.984253Z","shell.execute_reply.started":"2024-04-20T15:05:42.976347Z","shell.execute_reply":"2024-04-20T15:05:42.983190Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"'cpu'"},"metadata":{}}]},{"cell_type":"code","source":"class TABPFNModel(nn.Module):\n    def __init__(self, input_dim, hidden_dims, dropout):\n        super(TABPFNModel, self).__init__()\n        layers = []\n        prev_dim = input_dim\n        for dim in hidden_dims:\n            layers.append(nn.Linear(prev_dim, dim))\n            layers.append(nn.ReLU())\n            layers.append(nn.Dropout(dropout))\n            prev_dim = dim\n        layers.append(nn.Linear(prev_dim, 1))\n        self.model = nn.Sequential(*layers)\n    \n    def forward(self, x):\n        return self.model(x)","metadata":{"execution":{"iopub.status.busy":"2024-04-20T15:13:37.443075Z","iopub.execute_input":"2024-04-20T15:13:37.443504Z","iopub.status.idle":"2024-04-20T15:13:37.450417Z","shell.execute_reply.started":"2024-04-20T15:13:37.443470Z","shell.execute_reply":"2024-04-20T15:13:37.449374Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"params = {'hidden_dims': [144], \n          'dropout': 0.4100531293444458\n         }\ninput_dim = X_train_tensor.shape[1]\nmodel = TABPFNModel(input_dim, **params)","metadata":{"execution":{"iopub.status.busy":"2024-04-20T15:14:27.577429Z","iopub.execute_input":"2024-04-20T15:14:27.577824Z","iopub.status.idle":"2024-04-20T15:14:27.584788Z","shell.execute_reply.started":"2024-04-20T15:14:27.577797Z","shell.execute_reply":"2024-04-20T15:14:27.583751Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Initialize variables for early stopping\nbest_val_loss = float('inf')  # Initialize best_val_loss here\nbest_model_state = None\npatience_counter = 0\nearly_stopping_patience = 7  # Define the patience for early stopping\n\n\nEPOCHS = 45\ninitial_lr = 0.006  # Start with a small learning rate\nlr_step_size = 6   # Update the learning rate every 6 epochs\nlr_gamma = 0.1      # Multiply the learning rate by 0.1 every lr_step_size epochs\ncriterion = nn.MSELoss()\n\n# Define your optimizer\noptimizer = torch.optim.Adam(model.parameters(), lr=initial_lr)\n\n# Define your learning rate scheduler\nscheduler = StepLR(optimizer, step_size=lr_step_size, gamma=lr_gamma)\n\ntrain_losses = []\nval_losses = []\n\nfor epoch in trange(EPOCHS):\n    # Training phase\n    avg_train_loss = []\n    model.train()  # Set model to training mode\n    for i, (image, mask) in enumerate(tqdm(train_loader)):\n        image, mask = image.to(device), mask.to(device)\n        optimizer.zero_grad()\n        output = model(image)\n        mask = mask.view(-1, 1) \n        loss = criterion(output, mask)\n        loss.backward()\n        optimizer.step()\n        avg_train_loss.append(loss.item())\n\n    avg_train_loss = np.mean(avg_train_loss)\n\n    # Validation phase\n    avg_val_loss = []\n    model.eval()  # Set model to evaluation mode\n    for j, (image, mask) in enumerate(tqdm(val_loader)):\n        image, mask = image.to(device), mask.to(device)\n        with torch.no_grad():\n            output = model(image)\n            mask = mask.view(-1, 1)\n            loss = criterion(output, mask)\n            avg_val_loss.append(loss.item())\n\n    avg_val_loss = np.mean(avg_val_loss)\n\n     # Check for early stopping\n    if avg_val_loss < best_val_loss:\n        best_val_loss = avg_val_loss\n        best_model_state = model.state_dict()\n        patience_counter = 0\n    else:\n        patience_counter += 1\n        if patience_counter >= early_stopping_patience:\n            print(f\"Early stopping at epoch {epoch+1}\")\n            break\n    \n    tqdm.write(f\"Epoch [{epoch+1}/{EPOCHS}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n\n    # Apply learning rate scheduling\n    scheduler.step()\n\n    # Append the losses for this epoch\n    train_losses.append(avg_train_loss)\n    val_losses.append(avg_val_loss)\n\n# Create a DataFrame to store the losses\nloss_df = pd.DataFrame({'val_loss': val_losses, 'train_loss': train_losses})\n\n# Plot the losses\nplt.plot(loss_df.index + 1, loss_df['train_loss'], label='Train Loss')\nplt.plot(loss_df.index + 1, loss_df['val_loss'], label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Training and Validation Losses')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-20T15:14:29.556153Z","iopub.execute_input":"2024-04-20T15:14:29.557109Z","iopub.status.idle":"2024-04-20T15:15:04.923337Z","shell.execute_reply.started":"2024-04-20T15:14:29.557076Z","shell.execute_reply":"2024-04-20T15:15:04.922141Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/45 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9bd971133c164e22bccb45c263c8f111"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/543 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1812895e3f48401985e4f8f9e5683467"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/201 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c60bfdaceb64e699ad26174f8a0b476"}},"metadata":{}},{"name":"stdout","text":"Epoch [1/45], Train Loss: 8.6998, Val Loss: 4.5271\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/543 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"806f6821e45b4fa3b162613f9cb3f199"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/201 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df8e3e0059cf4a96a1017c3b685be90b"}},"metadata":{}},{"name":"stdout","text":"Epoch [2/45], Train Loss: 5.0821, Val Loss: 4.3615\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/543 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15cb2a5f27074d2898be8dcead08b879"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/201 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b8a220c07e149faba50dc921e7f6112"}},"metadata":{}},{"name":"stdout","text":"Epoch [3/45], Train Loss: 4.8339, Val Loss: 3.9305\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/543 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31c6fec672064cd4a92ed3ce1cadee2b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/201 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f33e9a83fe174c72ab1566f14bb6508b"}},"metadata":{}},{"name":"stdout","text":"Epoch [4/45], Train Loss: 4.6971, Val Loss: 3.9134\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/543 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0805ae49b8ec42639ad4c2567f2485d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/201 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a492c5eb7fd4474da6e06e1df21cdfb3"}},"metadata":{}},{"name":"stdout","text":"Epoch [5/45], Train Loss: 4.5871, Val Loss: 3.8809\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/543 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"735bc771b1974ba5b3fead9c8137002b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/201 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb167ea9a4c142af92514a5d032c752c"}},"metadata":{}},{"name":"stdout","text":"Epoch [6/45], Train Loss: 4.5383, Val Loss: 3.8288\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/543 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28661c1c912947c489cad6d87774210e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/201 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6a4d35f6f6f45f48814230f898fb5cb"}},"metadata":{}},{"name":"stdout","text":"Epoch [7/45], Train Loss: 4.3653, Val Loss: 3.8075\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/543 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a866704f70084d10a5bf6c35313c340d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/201 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"570b14ce03fe42c89144ef9036bf0839"}},"metadata":{}},{"name":"stdout","text":"Epoch [8/45], Train Loss: 4.3803, Val Loss: 3.8090\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/543 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14f0837bbf904563924cd79271fa7c6b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/201 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f5d8ef3fcb2473786f6015273279416"}},"metadata":{}},{"name":"stdout","text":"Epoch [9/45], Train Loss: 4.3286, Val Loss: 3.8044\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/543 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2cefbf63dd5d4eaabc861cb992298aee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/201 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8478c0fe0ff4b8e900c7b58cd8c0558"}},"metadata":{}},{"name":"stdout","text":"Epoch [10/45], Train Loss: 4.3431, Val Loss: 3.8055\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/543 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bff9661f73674b5b9e6e5309db44a295"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/201 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59f9dc51ccd74c2b87ae623325a0e72e"}},"metadata":{}},{"name":"stdout","text":"Epoch [11/45], Train Loss: 4.3146, Val Loss: 3.7992\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/543 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2789297c717749809450a278323df894"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/201 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83b9256f1e344095a80df9a4240995c9"}},"metadata":{}},{"name":"stdout","text":"Epoch [12/45], Train Loss: 4.3003, Val Loss: 3.8152\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/543 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0848ef4afb0e485992df2a0bbf9eb71e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/201 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c11cfe8316d4a97aebf6b094be07c0c"}},"metadata":{}},{"name":"stdout","text":"Epoch [13/45], Train Loss: 4.3092, Val Loss: 3.8049\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/543 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ef229dd0c014d33bb3d7908bcdd908e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/201 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99db6e9bd2094db68eb949551ebc340b"}},"metadata":{}},{"name":"stdout","text":"Epoch [14/45], Train Loss: 4.3161, Val Loss: 3.7989\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/543 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83747fd6856f4d20a031a96b56d66b04"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/201 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9dca5ae3f0d4b6ab1057ee638c0f8c1"}},"metadata":{}},{"name":"stdout","text":"Epoch [15/45], Train Loss: 4.3180, Val Loss: 3.7995\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/543 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"928905020864407faf29f8c6f810de70"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/201 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"917b4f1f5f3e422bafe6ee7fbfcea294"}},"metadata":{}},{"name":"stdout","text":"Epoch [16/45], Train Loss: 4.3121, Val Loss: 3.8000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/543 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58ad77b3da5845bbb678f015741c0b12"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/201 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5eeb84727b3841d9906831548693aa44"}},"metadata":{}},{"name":"stdout","text":"Epoch [17/45], Train Loss: 4.2967, Val Loss: 3.7983\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/543 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d03420f783d482e94f61709bed0f944"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/201 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0460fa0f8bf4d10be91a87e958cb983"}},"metadata":{}},{"name":"stdout","text":"Epoch [18/45], Train Loss: 4.2937, Val Loss: 3.7993\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/543 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"805d007c24814784969bbdc9cdbf4e00"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/201 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b2f0905d7de4fefa6ec015317b4d558"}},"metadata":{}},{"name":"stdout","text":"Epoch [19/45], Train Loss: 4.2909, Val Loss: 3.8004\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/543 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57d9864db16642ceadfb1c1357c2fcb9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/201 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e2e878237e34b708298ca71e9797780"}},"metadata":{}},{"name":"stdout","text":"Epoch [20/45], Train Loss: 4.2926, Val Loss: 3.8006\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/543 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"543192aee00f44e4a05b724e5c00db90"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/201 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c44dfd48a765469da902faf984c79853"}},"metadata":{}},{"name":"stdout","text":"Epoch [21/45], Train Loss: 4.3002, Val Loss: 3.7998\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/543 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e17a5d30cfd146148f523b583a8f937f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/201 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d80569f6ee53452d98fe1bafc8580589"}},"metadata":{}},{"name":"stdout","text":"Epoch [22/45], Train Loss: 4.2909, Val Loss: 3.7997\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/543 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e199326aa98475d838752dcaa6a401f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/201 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d51e343289ba4336978132c09317d5ab"}},"metadata":{}},{"name":"stdout","text":"Epoch [23/45], Train Loss: 4.2938, Val Loss: 3.8003\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/543 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c87442ecb8cb463b8570c7638176af6d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/201 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"918a58d57cdd41f6b261611722ed68f1"}},"metadata":{}},{"name":"stdout","text":"Early stopping at epoch 24\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"# Inference\nwith torch.no_grad():\n    model.eval()\n    predictions = model(X_val_tensor.to(device)).cpu().numpy()\n    RMSE = np.sqrt(mean_squared_error(y_val_tensor, predictions.reshape(-1, 1)))\nRMSE","metadata":{"execution":{"iopub.status.busy":"2024-04-20T15:16:41.270897Z","iopub.execute_input":"2024-04-20T15:16:41.271318Z","iopub.status.idle":"2024-04-20T15:16:41.299167Z","shell.execute_reply.started":"2024-04-20T15:16:41.271284Z","shell.execute_reply":"2024-04-20T15:16:41.297965Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"1.9494407"},"metadata":{}}]},{"cell_type":"markdown","source":"## Hyperparameter tune","metadata":{}},{"cell_type":"code","source":"def train_model(X_train_tensor, y_train_tensor, val_loader, params):\n    input_dim = params['input_dim']\n    hidden_dims = params['hidden_dims']\n    dropout = params['dropout']\n    num_epochs = 200\n    batch_size = 122\n    learning_rate = 0.001\n    \n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    model = TABPFNModel(input_dim, hidden_dims, dropout).to(device)\n    \n    criterion = nn.MSELoss()\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n    \n    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    \n    best_val_loss = float('inf')  # Initialize best_val_loss here\n    best_model_state = None\n    patience_counter = 0\n    early_stopping_patience = 7  # Define the patience for early stopping\n    \n    for epoch in tqdm(range(num_epochs)):\n        model.train()\n        epoch_train_loss = 0.0\n        for batch_X, batch_y in train_loader:\n            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n            optimizer.zero_grad()\n            outputs = model(batch_X)\n            loss = criterion(outputs, batch_y)\n            loss.backward()\n            optimizer.step()\n            epoch_train_loss += loss.item() * batch_X.size(0)\n        \n        # Calculate validation loss after each epoch\n        model.eval()\n        with torch.no_grad():\n            val_loss = 0\n            for batch_X, batch_y in val_loader:\n                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n                outputs = model(batch_X)\n                val_loss += criterion(outputs, batch_y).item() * batch_X.size(0)\n            avg_val_loss = val_loss / len(val_loader.dataset)\n        \n        # Log training and validation loss for each epoch\n        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_train_loss / len(train_loader.dataset):.4f}, Validation Loss: {avg_val_loss:.4f}\")\n        \n        # Check for early stopping\n        if avg_val_loss < best_val_loss:\n            best_val_loss = avg_val_loss\n            best_model_state = model.state_dict()\n            patience_counter = 0\n        else:\n            patience_counter += 1\n            if patience_counter >= early_stopping_patience:\n                print(f\"Early stopping at epoch {epoch+1}\")\n                break\n    \n    # Load the best model state\n    model.load_state_dict(best_model_state)\n    \n    return model\n\ndef objective(trial):\n    input_dim = X_train.shape[1]\n    hidden_dims = [trial.suggest_int(f'n_units_{i}', 32, 256) for i in range(trial.suggest_int('n_layers', 1, 4))]\n    dropout = trial.suggest_float('dropout', 0.1, 0.5)\n    \n    params = {\n        'input_dim': input_dim,\n        'hidden_dims': hidden_dims,\n        'dropout': dropout\n    }\n    \n    model = train_model(X_train_tensor, y_train_tensor, val_loader, params)\n    \n    model.eval()\n    predictions = []\n    with torch.no_grad():\n        for batch_X, _ in tqdm(val_loader):\n            batch_X = batch_X.to(device)\n            outputs = model(batch_X)\n            predictions.append(outputs.cpu().numpy())\n    \n    predictions = np.concatenate(predictions)\n    val_rmse = np.sqrt(mean_squared_error(y_val, predictions))\n    \n    return val_rmse\n\nstudy = optuna.create_study(direction='minimize')\nstudy.optimize(objective, n_trials=100)\n\nprint(\"Best hyperparameters:\", study.best_params)\nprint(\"Best validation RMSE:\", study.best_value)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-20T15:05:49.050296Z","iopub.execute_input":"2024-04-20T15:05:49.050677Z","iopub.status.idle":"2024-04-20T15:13:35.088054Z","shell.execute_reply.started":"2024-04-20T15:05:49.050647Z","shell.execute_reply":"2024-04-20T15:13:35.086337Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"[I 2024-04-20 15:05:49,067] A new study created in memory with name: no-name-4a28b52a-e19d-41e4-8b31-4679c23868e5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9226988b6f442fa8fb49f8e9ab58f7a"}},"metadata":{}},{"name":"stdout","text":"Epoch [1/200], Train Loss: 10.4033, Validation Loss: 6.2564\nEpoch [2/200], Train Loss: 6.5193, Validation Loss: 5.8946\nEpoch [3/200], Train Loss: 5.7808, Validation Loss: 4.3284\nEpoch [4/200], Train Loss: 5.4704, Validation Loss: 4.1409\nEpoch [5/200], Train Loss: 5.2268, Validation Loss: 4.1971\nEpoch [6/200], Train Loss: 5.0714, Validation Loss: 3.7510\nEpoch [7/200], Train Loss: 4.9515, Validation Loss: 3.7800\nEpoch [8/200], Train Loss: 4.8870, Validation Loss: 3.7459\nEpoch [9/200], Train Loss: 4.8582, Validation Loss: 3.7157\nEpoch [10/200], Train Loss: 4.7951, Validation Loss: 3.6744\nEpoch [11/200], Train Loss: 4.7256, Validation Loss: 3.9373\nEpoch [12/200], Train Loss: 4.6687, Validation Loss: 3.6798\nEpoch [13/200], Train Loss: 4.6173, Validation Loss: 3.6379\nEpoch [14/200], Train Loss: 4.5825, Validation Loss: 3.6542\nEpoch [15/200], Train Loss: 4.5657, Validation Loss: 3.6524\nEpoch [16/200], Train Loss: 4.5705, Validation Loss: 3.6774\nEpoch [17/200], Train Loss: 4.5099, Validation Loss: 3.6551\nEpoch [18/200], Train Loss: 4.4560, Validation Loss: 3.7439\nEpoch [19/200], Train Loss: 4.4326, Validation Loss: 3.6110\nEpoch [20/200], Train Loss: 4.4568, Validation Loss: 3.6115\nEpoch [21/200], Train Loss: 4.4153, Validation Loss: 3.7765\nEpoch [22/200], Train Loss: 4.3912, Validation Loss: 3.6475\nEpoch [23/200], Train Loss: 4.3613, Validation Loss: 3.7202\nEpoch [24/200], Train Loss: 4.3029, Validation Loss: 3.7177\nEpoch [25/200], Train Loss: 4.3265, Validation Loss: 3.6869\nEpoch [26/200], Train Loss: 4.2689, Validation Loss: 3.5701\nEpoch [27/200], Train Loss: 4.2552, Validation Loss: 3.6424\nEpoch [28/200], Train Loss: 4.2693, Validation Loss: 3.7377\nEpoch [29/200], Train Loss: 4.2280, Validation Loss: 3.5640\nEpoch [30/200], Train Loss: 4.2017, Validation Loss: 3.5583\nEpoch [31/200], Train Loss: 4.2048, Validation Loss: 3.5902\nEpoch [32/200], Train Loss: 4.1922, Validation Loss: 3.6403\nEpoch [33/200], Train Loss: 4.1557, Validation Loss: 3.5712\nEpoch [34/200], Train Loss: 4.1555, Validation Loss: 3.5654\nEpoch [35/200], Train Loss: 4.1318, Validation Loss: 3.5707\nEpoch [36/200], Train Loss: 4.1145, Validation Loss: 3.5775\nEpoch [37/200], Train Loss: 4.0896, Validation Loss: 3.5922\nEarly stopping at epoch 37\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/201 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3336f367edc14c299c84f80c52632eb9"}},"metadata":{}},{"name":"stderr","text":"[I 2024-04-20 15:07:30,571] Trial 0 finished with value: 1.8953091232462542 and parameters: {'n_layers': 3, 'n_units_0': 161, 'n_units_1': 251, 'n_units_2': 174, 'dropout': 0.476162853385801}. Best is trial 0 with value: 1.8953091232462542.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"422b463d818241ce87c618767daa0bf0"}},"metadata":{}},{"name":"stdout","text":"Epoch [1/200], Train Loss: 9.1291, Validation Loss: 4.7868\nEpoch [2/200], Train Loss: 5.4915, Validation Loss: 6.4760\nEpoch [3/200], Train Loss: 5.0134, Validation Loss: 4.1759\nEpoch [4/200], Train Loss: 4.8406, Validation Loss: 3.9709\nEpoch [5/200], Train Loss: 4.7290, Validation Loss: 4.2008\nEpoch [6/200], Train Loss: 4.6330, Validation Loss: 3.8199\nEpoch [7/200], Train Loss: 4.5480, Validation Loss: 3.7917\nEpoch [8/200], Train Loss: 4.5191, Validation Loss: 3.6350\nEpoch [9/200], Train Loss: 4.4858, Validation Loss: 3.8297\nEpoch [10/200], Train Loss: 4.4879, Validation Loss: 3.8186\nEpoch [11/200], Train Loss: 4.4656, Validation Loss: 3.6076\nEpoch [12/200], Train Loss: 4.4031, Validation Loss: 3.7788\nEpoch [13/200], Train Loss: 4.2953, Validation Loss: 3.6914\nEpoch [14/200], Train Loss: 4.3144, Validation Loss: 3.6857\nEpoch [15/200], Train Loss: 4.2450, Validation Loss: 3.5511\nEpoch [16/200], Train Loss: 4.2173, Validation Loss: 3.5751\nEpoch [17/200], Train Loss: 4.2160, Validation Loss: 3.6330\nEpoch [18/200], Train Loss: 4.2010, Validation Loss: 3.6577\nEpoch [19/200], Train Loss: 4.1703, Validation Loss: 3.5660\nEpoch [20/200], Train Loss: 4.1695, Validation Loss: 3.7579\nEpoch [21/200], Train Loss: 4.1753, Validation Loss: 3.5793\nEpoch [22/200], Train Loss: 4.1365, Validation Loss: 3.9550\nEarly stopping at epoch 22\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/201 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b36d03aac54481a90288396d3bbe2d8"}},"metadata":{}},{"name":"stderr","text":"[I 2024-04-20 15:08:36,824] Trial 1 finished with value: 1.9887059638074114 and parameters: {'n_layers': 4, 'n_units_0': 135, 'n_units_1': 144, 'n_units_2': 233, 'n_units_3': 189, 'dropout': 0.2910903212827516}. Best is trial 0 with value: 1.8953091232462542.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ccc3103a96a4f9f85c4dad7824def8b"}},"metadata":{}},{"name":"stdout","text":"Epoch [1/200], Train Loss: 19.9787, Validation Loss: 5.8894\nEpoch [2/200], Train Loss: 7.1629, Validation Loss: 5.6053\nEpoch [3/200], Train Loss: 6.7277, Validation Loss: 5.2311\nEpoch [4/200], Train Loss: 6.3829, Validation Loss: 4.9141\nEpoch [5/200], Train Loss: 6.0864, Validation Loss: 4.6483\nEpoch [6/200], Train Loss: 5.7699, Validation Loss: 4.3850\nEpoch [7/200], Train Loss: 5.5021, Validation Loss: 4.2203\nEpoch [8/200], Train Loss: 5.2983, Validation Loss: 4.0592\nEpoch [9/200], Train Loss: 5.1927, Validation Loss: 4.0202\nEpoch [10/200], Train Loss: 5.0964, Validation Loss: 3.9668\nEpoch [11/200], Train Loss: 5.0184, Validation Loss: 3.9453\nEpoch [12/200], Train Loss: 4.9541, Validation Loss: 3.9274\nEpoch [13/200], Train Loss: 4.8900, Validation Loss: 3.9330\nEpoch [14/200], Train Loss: 4.8136, Validation Loss: 3.9230\nEpoch [15/200], Train Loss: 4.7998, Validation Loss: 3.8745\nEpoch [16/200], Train Loss: 4.7423, Validation Loss: 3.8935\nEpoch [17/200], Train Loss: 4.6921, Validation Loss: 3.8547\nEpoch [18/200], Train Loss: 4.6450, Validation Loss: 3.8527\nEpoch [19/200], Train Loss: 4.6054, Validation Loss: 3.8369\nEpoch [20/200], Train Loss: 4.5672, Validation Loss: 3.8269\nEpoch [21/200], Train Loss: 4.5123, Validation Loss: 3.8287\nEpoch [22/200], Train Loss: 4.4732, Validation Loss: 3.8194\nEpoch [23/200], Train Loss: 4.4737, Validation Loss: 3.8485\nEpoch [24/200], Train Loss: 4.3831, Validation Loss: 3.8021\nEpoch [25/200], Train Loss: 4.3773, Validation Loss: 3.8060\nEpoch [26/200], Train Loss: 4.3276, Validation Loss: 3.8588\nEpoch [27/200], Train Loss: 4.3156, Validation Loss: 3.8014\nEpoch [28/200], Train Loss: 4.2890, Validation Loss: 3.8046\nEpoch [29/200], Train Loss: 4.2489, Validation Loss: 3.7957\nEpoch [30/200], Train Loss: 4.2249, Validation Loss: 3.7989\nEpoch [31/200], Train Loss: 4.2310, Validation Loss: 3.7849\nEpoch [32/200], Train Loss: 4.2095, Validation Loss: 3.8196\nEpoch [33/200], Train Loss: 4.1893, Validation Loss: 3.7762\nEpoch [34/200], Train Loss: 4.1742, Validation Loss: 3.7767\nEpoch [35/200], Train Loss: 4.1551, Validation Loss: 3.7850\nEpoch [36/200], Train Loss: 4.1206, Validation Loss: 3.7749\nEpoch [37/200], Train Loss: 4.1108, Validation Loss: 3.7665\nEpoch [38/200], Train Loss: 4.1339, Validation Loss: 3.7744\nEpoch [39/200], Train Loss: 4.0867, Validation Loss: 3.7597\nEpoch [40/200], Train Loss: 4.0847, Validation Loss: 3.7531\nEpoch [41/200], Train Loss: 4.0945, Validation Loss: 3.7578\nEpoch [42/200], Train Loss: 4.0635, Validation Loss: 3.7392\nEpoch [43/200], Train Loss: 4.0581, Validation Loss: 3.7488\nEpoch [44/200], Train Loss: 4.0520, Validation Loss: 3.7478\nEpoch [45/200], Train Loss: 4.0526, Validation Loss: 3.7410\nEpoch [46/200], Train Loss: 4.0233, Validation Loss: 3.7480\nEpoch [47/200], Train Loss: 4.0067, Validation Loss: 3.7357\nEpoch [48/200], Train Loss: 4.0305, Validation Loss: 3.7612\nEpoch [49/200], Train Loss: 4.0456, Validation Loss: 3.7350\nEpoch [50/200], Train Loss: 4.0312, Validation Loss: 3.7372\nEpoch [51/200], Train Loss: 4.0324, Validation Loss: 3.7460\nEpoch [52/200], Train Loss: 4.0211, Validation Loss: 3.7606\nEpoch [53/200], Train Loss: 3.9982, Validation Loss: 3.7433\nEpoch [54/200], Train Loss: 4.0027, Validation Loss: 3.7351\nEpoch [55/200], Train Loss: 4.0110, Validation Loss: 3.7448\nEpoch [56/200], Train Loss: 4.0283, Validation Loss: 3.7301\nEpoch [57/200], Train Loss: 4.0055, Validation Loss: 3.7240\nEpoch [58/200], Train Loss: 3.9834, Validation Loss: 3.7350\nEpoch [59/200], Train Loss: 4.0205, Validation Loss: 3.7364\nEpoch [60/200], Train Loss: 3.9978, Validation Loss: 3.7670\nEpoch [61/200], Train Loss: 3.9927, Validation Loss: 3.7307\nEpoch [62/200], Train Loss: 3.9973, Validation Loss: 3.7403\nEpoch [63/200], Train Loss: 3.9734, Validation Loss: 3.7192\nEpoch [64/200], Train Loss: 3.9765, Validation Loss: 3.7060\nEpoch [65/200], Train Loss: 3.9778, Validation Loss: 3.7126\nEpoch [66/200], Train Loss: 3.9888, Validation Loss: 3.7229\nEpoch [67/200], Train Loss: 3.9923, Validation Loss: 3.7342\nEpoch [68/200], Train Loss: 3.9701, Validation Loss: 3.7667\nEpoch [69/200], Train Loss: 3.9774, Validation Loss: 3.7052\nEpoch [70/200], Train Loss: 3.9819, Validation Loss: 3.7161\nEpoch [71/200], Train Loss: 3.9968, Validation Loss: 3.7054\nEpoch [72/200], Train Loss: 3.9726, Validation Loss: 3.7099\nEpoch [73/200], Train Loss: 3.9613, Validation Loss: 3.7125\nEpoch [74/200], Train Loss: 3.9672, Validation Loss: 3.7001\nEpoch [75/200], Train Loss: 3.9643, Validation Loss: 3.7069\nEpoch [76/200], Train Loss: 3.9695, Validation Loss: 3.6930\nEpoch [77/200], Train Loss: 3.9622, Validation Loss: 3.7033\nEpoch [78/200], Train Loss: 3.9399, Validation Loss: 3.7067\nEpoch [79/200], Train Loss: 3.9527, Validation Loss: 3.6956\nEpoch [80/200], Train Loss: 3.9694, Validation Loss: 3.6906\nEpoch [81/200], Train Loss: 3.9681, Validation Loss: 3.6934\nEpoch [82/200], Train Loss: 3.9801, Validation Loss: 3.7029\nEpoch [83/200], Train Loss: 3.9556, Validation Loss: 3.7056\nEpoch [84/200], Train Loss: 3.9639, Validation Loss: 3.6961\nEpoch [85/200], Train Loss: 3.9429, Validation Loss: 3.6968\nEpoch [86/200], Train Loss: 3.9595, Validation Loss: 3.6954\nEpoch [87/200], Train Loss: 3.9531, Validation Loss: 3.7010\nEarly stopping at epoch 87\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/201 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5772f2e0d1b74c198a25040512321b10"}},"metadata":{}},{"name":"stderr","text":"[I 2024-04-20 15:10:33,554] Trial 2 finished with value: 1.9238096116924044 and parameters: {'n_layers': 1, 'n_units_0': 129, 'dropout': 0.49940951926184507}. Best is trial 0 with value: 1.8953091232462542.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7654d4cc8c3435ba1faeac14dd9cf38"}},"metadata":{}},{"name":"stdout","text":"Epoch [1/200], Train Loss: 13.2708, Validation Loss: 5.6311\nEpoch [2/200], Train Loss: 6.8755, Validation Loss: 4.2118\nEpoch [3/200], Train Loss: 5.6829, Validation Loss: 4.4938\nEpoch [4/200], Train Loss: 5.2429, Validation Loss: 3.9111\nEpoch [5/200], Train Loss: 5.0512, Validation Loss: 3.9221\nEpoch [6/200], Train Loss: 4.9051, Validation Loss: 3.8449\nEpoch [7/200], Train Loss: 4.8362, Validation Loss: 3.8922\nEpoch [8/200], Train Loss: 4.7622, Validation Loss: 3.7668\nEpoch [9/200], Train Loss: 4.6940, Validation Loss: 3.8298\nEpoch [10/200], Train Loss: 4.6431, Validation Loss: 3.9158\nEpoch [11/200], Train Loss: 4.6337, Validation Loss: 3.7457\nEpoch [12/200], Train Loss: 4.5856, Validation Loss: 3.7086\nEpoch [13/200], Train Loss: 4.5696, Validation Loss: 3.7065\nEpoch [14/200], Train Loss: 4.5517, Validation Loss: 3.8302\nEpoch [15/200], Train Loss: 4.5396, Validation Loss: 3.7311\nEpoch [16/200], Train Loss: 4.5431, Validation Loss: 3.9198\nEpoch [17/200], Train Loss: 4.5457, Validation Loss: 3.7598\nEpoch [18/200], Train Loss: 4.4713, Validation Loss: 3.6598\nEpoch [19/200], Train Loss: 4.5063, Validation Loss: 3.6411\nEpoch [20/200], Train Loss: 4.4499, Validation Loss: 3.8290\nEpoch [21/200], Train Loss: 4.4733, Validation Loss: 3.6801\nEpoch [22/200], Train Loss: 4.4358, Validation Loss: 3.6723\nEpoch [23/200], Train Loss: 4.3972, Validation Loss: 3.6840\nEpoch [24/200], Train Loss: 4.4054, Validation Loss: 3.6108\nEpoch [25/200], Train Loss: 4.3649, Validation Loss: 3.6325\nEpoch [26/200], Train Loss: 4.3816, Validation Loss: 3.6990\nEpoch [27/200], Train Loss: 4.3405, Validation Loss: 3.6149\nEpoch [28/200], Train Loss: 4.3863, Validation Loss: 3.6818\nEpoch [29/200], Train Loss: 4.3280, Validation Loss: 3.6492\nEpoch [30/200], Train Loss: 4.3063, Validation Loss: 3.7892\nEpoch [31/200], Train Loss: 4.3096, Validation Loss: 3.6723\nEarly stopping at epoch 31\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/201 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c62c9c933b540ff86cdeb4f204d1144"}},"metadata":{}},{"name":"stderr","text":"[I 2024-04-20 15:11:33,347] Trial 3 finished with value: 1.916324826869176 and parameters: {'n_layers': 3, 'n_units_0': 69, 'n_units_1': 57, 'n_units_2': 203, 'dropout': 0.41697310599922577}. Best is trial 0 with value: 1.8953091232462542.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d70b0b34b9f4394833b9616d9d7c268"}},"metadata":{}},{"name":"stdout","text":"Epoch [1/200], Train Loss: 9.4766, Validation Loss: 4.9154\nEpoch [2/200], Train Loss: 5.4188, Validation Loss: 4.0977\nEpoch [3/200], Train Loss: 4.9129, Validation Loss: 3.8849\nEpoch [4/200], Train Loss: 4.6621, Validation Loss: 3.9822\nEpoch [5/200], Train Loss: 4.5777, Validation Loss: 3.9482\nEpoch [6/200], Train Loss: 4.4236, Validation Loss: 3.9663\nEpoch [7/200], Train Loss: 4.3889, Validation Loss: 3.7242\nEpoch [8/200], Train Loss: 4.3045, Validation Loss: 3.7083\nEpoch [9/200], Train Loss: 4.2580, Validation Loss: 3.6828\nEpoch [10/200], Train Loss: 4.2159, Validation Loss: 3.7127\nEpoch [11/200], Train Loss: 4.1580, Validation Loss: 3.6851\nEpoch [12/200], Train Loss: 4.1460, Validation Loss: 3.6699\nEpoch [13/200], Train Loss: 4.1285, Validation Loss: 3.6894\nEpoch [14/200], Train Loss: 4.0945, Validation Loss: 3.7407\nEpoch [15/200], Train Loss: 4.1010, Validation Loss: 3.6492\nEpoch [16/200], Train Loss: 4.0430, Validation Loss: 3.6903\nEpoch [17/200], Train Loss: 4.0352, Validation Loss: 3.6905\nEpoch [18/200], Train Loss: 4.0464, Validation Loss: 3.6142\nEpoch [19/200], Train Loss: 4.0207, Validation Loss: 3.6401\nEpoch [20/200], Train Loss: 3.9969, Validation Loss: 3.6187\nEpoch [21/200], Train Loss: 3.9666, Validation Loss: 3.6406\nEpoch [22/200], Train Loss: 3.9826, Validation Loss: 3.5834\nEpoch [23/200], Train Loss: 3.9695, Validation Loss: 3.6219\nEpoch [24/200], Train Loss: 3.9622, Validation Loss: 3.5904\nEpoch [25/200], Train Loss: 3.9682, Validation Loss: 3.5834\nEpoch [26/200], Train Loss: 3.9307, Validation Loss: 3.5954\nEpoch [27/200], Train Loss: 3.9473, Validation Loss: 3.6026\nEpoch [28/200], Train Loss: 3.9179, Validation Loss: 3.5700\nEpoch [29/200], Train Loss: 3.9159, Validation Loss: 3.6843\nEpoch [30/200], Train Loss: 3.8973, Validation Loss: 3.6002\nEpoch [31/200], Train Loss: 3.8958, Validation Loss: 3.5530\nEpoch [32/200], Train Loss: 3.9087, Validation Loss: 3.5438\nEpoch [33/200], Train Loss: 3.8988, Validation Loss: 3.5472\nEpoch [34/200], Train Loss: 3.8863, Validation Loss: 3.5271\nEpoch [35/200], Train Loss: 3.8652, Validation Loss: 3.5399\nEpoch [36/200], Train Loss: 3.8950, Validation Loss: 3.5394\nEpoch [37/200], Train Loss: 3.8641, Validation Loss: 3.5388\nEpoch [38/200], Train Loss: 3.8779, Validation Loss: 3.5229\nEpoch [39/200], Train Loss: 3.8622, Validation Loss: 3.5715\nEpoch [40/200], Train Loss: 3.8496, Validation Loss: 3.5612\nEpoch [41/200], Train Loss: 3.8522, Validation Loss: 3.5795\nEpoch [42/200], Train Loss: 3.8543, Validation Loss: 3.5792\nEpoch [43/200], Train Loss: 3.8178, Validation Loss: 3.5113\nEpoch [44/200], Train Loss: 3.8382, Validation Loss: 3.5281\nEpoch [45/200], Train Loss: 3.8533, Validation Loss: 3.5210\nEpoch [46/200], Train Loss: 3.8350, Validation Loss: 3.5574\nEpoch [47/200], Train Loss: 3.8313, Validation Loss: 3.5428\nEpoch [48/200], Train Loss: 3.8278, Validation Loss: 3.5035\nEpoch [49/200], Train Loss: 3.8440, Validation Loss: 3.5304\nEpoch [50/200], Train Loss: 3.8216, Validation Loss: 3.5694\nEpoch [51/200], Train Loss: 3.8082, Validation Loss: 3.5145\nEpoch [52/200], Train Loss: 3.8138, Validation Loss: 3.5023\nEpoch [53/200], Train Loss: 3.8050, Validation Loss: 3.5066\nEpoch [54/200], Train Loss: 3.8055, Validation Loss: 3.5339\nEpoch [55/200], Train Loss: 3.7936, Validation Loss: 3.6072\nEpoch [56/200], Train Loss: 3.8141, Validation Loss: 3.5068\nEpoch [57/200], Train Loss: 3.7956, Validation Loss: 3.5118\n","output_type":"stream"},{"name":"stderr","text":"[W 2024-04-20 15:13:34,407] Trial 4 failed with parameters: {'n_layers': 2, 'n_units_0': 193, 'n_units_1': 244, 'dropout': 0.33086235679533893} because of the following error: KeyboardInterrupt().\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n    value_or_values = func(trial)\n  File \"/tmp/ipykernel_34/1588159313.py\", line 76, in objective\n    model = train_model(X_train_tensor, y_train_tensor, val_loader, params)\n  File \"/tmp/ipykernel_34/1588159313.py\", line 32, in train_model\n    loss.backward()\n  File \"/opt/conda/lib/python3.10/site-packages/torch/_tensor.py\", line 492, in backward\n    torch.autograd.backward(\n  File \"/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 251, in backward\n    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\nKeyboardInterrupt\n[W 2024-04-20 15:13:34,411] Trial 4 failed with value None.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[6], line 92\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m val_rmse\n\u001b[1;32m     91\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 92\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest hyperparameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, study\u001b[38;5;241m.\u001b[39mbest_params)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest validation RMSE:\u001b[39m\u001b[38;5;124m\"\u001b[39m, study\u001b[38;5;241m.\u001b[39mbest_value)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/optuna/study/_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 62\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/optuna/study/_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/optuna/study/_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    246\u001b[0m ):\n\u001b[0;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/optuna/study/_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n","Cell \u001b[0;32mIn[6], line 76\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     68\u001b[0m dropout \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39msuggest_float(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdropout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m     70\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_dim\u001b[39m\u001b[38;5;124m'\u001b[39m: input_dim,\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhidden_dims\u001b[39m\u001b[38;5;124m'\u001b[39m: hidden_dims,\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdropout\u001b[39m\u001b[38;5;124m'\u001b[39m: dropout\n\u001b[1;32m     74\u001b[0m }\n\u001b[0;32m---> 76\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     79\u001b[0m predictions \u001b[38;5;241m=\u001b[39m []\n","Cell \u001b[0;32mIn[6], line 32\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(X_train_tensor, y_train_tensor, val_loader, params)\u001b[0m\n\u001b[1;32m     30\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(batch_X)\n\u001b[1;32m     31\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, batch_y)\n\u001b[0;32m---> 32\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     34\u001b[0m epoch_train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m batch_X\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]}]}