{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":72489,"databundleVersionId":8096274,"sourceType":"competition"}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch.nn as nn\nimport torch\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import StepLR\nimport pandas as pd\nimport numpy as np\nfrom tqdm.notebook import tqdm, trange\nimport optuna \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import MinMaxScaler, LabelEncoder\nfrom sklearn.model_selection import KFold\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2024-04-17T20:15:08.698398Z","iopub.execute_input":"2024-04-17T20:15:08.699262Z","iopub.status.idle":"2024-04-17T20:15:08.705131Z","shell.execute_reply.started":"2024-04-17T20:15:08.699227Z","shell.execute_reply":"2024-04-17T20:15:08.704095Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/playground-series-s4e4/train.csv')\ntest = pd.read_csv('/kaggle/input/playground-series-s4e4/test.csv')\ntrain.drop(columns=['id'], axis=1, inplace=True)\ntest.drop(columns=['id'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T20:15:10.789583Z","iopub.execute_input":"2024-04-17T20:15:10.789949Z","iopub.status.idle":"2024-04-17T20:15:11.060503Z","shell.execute_reply.started":"2024-04-17T20:15:10.789919Z","shell.execute_reply":"2024-04-17T20:15:11.059438Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Preprocess","metadata":{}},{"cell_type":"code","source":"encoder = LabelEncoder()\nscaler = MinMaxScaler()\ncat_cols = ['Sex']\ntarget = 'Rings'\ncontinous_cols = [col for col in train.columns if col not in cat_cols + [target]]\n\ntrain['Sex'] = encoder.fit_transform(train['Sex'])\ntest['Sex'] = encoder.transform(test['Sex'])\n\ntrain[continous_cols] = scaler.fit_transform(train[continous_cols])\ntest[continous_cols] = scaler.transform(test[continous_cols])\n\nX = train.drop(columns=[target], axis=1)\ny = train[target]\n\nX_train, X_val, y_train, y_val = train_test_split(X.values, y.values, \n                                                  test_size=0.25, random_state=24)\nX_train_tensor = torch.tensor(X_train, dtype=torch.float32)\nX_val_tensor = torch.tensor(X_val, dtype=torch.float32)\ny_train_tensor = torch.tensor(y_train, dtype=torch.float32)\ny_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n\nbatch_size = 77\ntrain_dataset = TensorDataset(X_train_tensor, y_train_tensor)\nval_dataset = TensorDataset(X_val_tensor, y_val_tensor)\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T20:15:12.738339Z","iopub.execute_input":"2024-04-17T20:15:12.738989Z","iopub.status.idle":"2024-04-17T20:15:12.851771Z","shell.execute_reply.started":"2024-04-17T20:15:12.738953Z","shell.execute_reply":"2024-04-17T20:15:12.850767Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-04-17T20:15:15.138341Z","iopub.execute_input":"2024-04-17T20:15:15.139193Z","iopub.status.idle":"2024-04-17T20:15:15.170243Z","shell.execute_reply.started":"2024-04-17T20:15:15.139160Z","shell.execute_reply":"2024-04-17T20:15:15.169288Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"markdown","source":"## Network","metadata":{}},{"cell_type":"code","source":"class NODEModel(nn.Module):\n    \"\"\"\n    Neural Oblivious Decision Ensembles (NODE) model.\n    \"\"\"\n    def __init__(self, input_dim, num_trees, depth):\n        \"\"\"\n        Initialize the NODE model.\n        \n        Args:\n            input_dim (int): Number of input features.\n            num_trees (int): Number of decision trees in the ensemble.\n            depth (int): Depth of each decision tree.\n        \"\"\"\n        super(NODEModel, self).__init__()\n        self.num_trees = num_trees\n        self.depth = depth\n        \n        # Create a list of decision trees\n        self.trees = nn.ModuleList([nn.Sequential(\n            nn.Linear(input_dim, 2 ** depth),\n            nn.ReLU(),\n            nn.Linear(2 ** depth, 1)\n        ) for _ in range(num_trees)])\n    \n    def forward(self, x):\n        \"\"\"\n        Perform forward pass through the NODE model.\n        \n        Args:\n            x (torch.Tensor): Input tensor.\n            \n        Returns:\n            torch.Tensor: Averaged predictions from all decision trees.\n        \"\"\"\n        # Forward pass through each decision tree\n        outputs = [tree(x).squeeze() for tree in self.trees]\n        \n        # Average the predictions from all trees\n        return torch.mean(torch.stack(outputs), dim=0)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T20:15:17.060794Z","iopub.execute_input":"2024-04-17T20:15:17.061848Z","iopub.status.idle":"2024-04-17T20:15:17.070092Z","shell.execute_reply.started":"2024-04-17T20:15:17.061810Z","shell.execute_reply":"2024-04-17T20:15:17.069088Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"input_dim = X_train_tensor.shape[1]\nparams = {'num_trees': 106, 'depth': 8}\n\nmodel = NODEModel(input_dim, **params).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T20:15:19.725408Z","iopub.execute_input":"2024-04-17T20:15:19.725800Z","iopub.status.idle":"2024-04-17T20:15:20.043359Z","shell.execute_reply.started":"2024-04-17T20:15:19.725770Z","shell.execute_reply":"2024-04-17T20:15:20.042557Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Train loop","metadata":{}},{"cell_type":"code","source":"# Initialize variables for early stopping\nbest_val_loss = float('inf')  # Initialize best_val_loss here\nbest_model_state = None\npatience_counter = 0\nearly_stopping_patience = 5  # Define the patience for early stopping\n\n\nEPOCHS = 35\ninitial_lr = 0.004  # Start with a small learning rate\nlr_step_size = 6   # Update the learning rate every 6 epochs\nlr_gamma = 0.1      # Multiply the learning rate by 0.1 every lr_step_size epochs\ncriterion = nn.MSELoss()\n\n# Define your optimizer\noptimizer = torch.optim.Adam(model.parameters(), lr=initial_lr)\n\n# Define your learning rate scheduler\nscheduler = StepLR(optimizer, step_size=lr_step_size, gamma=lr_gamma)\n\ntrain_losses = []\nval_losses = []\n\nfor epoch in trange(EPOCHS):\n    # Training phase\n    avg_train_loss = []\n    model.train()  # Set model to training mode\n    for i, (image, mask) in enumerate(tqdm(train_loader)):\n        image, mask = image.to(device), mask.to(device)\n        optimizer.zero_grad()\n        output = model(image)\n        loss = criterion(output, mask)\n        loss.backward()\n        optimizer.step()\n        avg_train_loss.append(loss.item())\n\n    avg_train_loss = np.mean(avg_train_loss)\n\n    # Validation phase\n    avg_val_loss = []\n    model.eval()  # Set model to evaluation mode\n    for j, (image, mask) in enumerate(tqdm(val_loader)):\n        image, mask = image.to(device), mask.to(device)\n        with torch.no_grad():\n            output = model(image)\n            loss = criterion(output, mask)\n            avg_val_loss.append(loss.item())\n\n    avg_val_loss = np.mean(avg_val_loss)\n\n     # Check for early stopping\n    if avg_val_loss < best_val_loss:\n        best_val_loss = avg_val_loss\n        best_model_state = model.state_dict()\n        patience_counter = 0\n    else:\n        patience_counter += 1\n        if patience_counter >= early_stopping_patience:\n            print(f\"Early stopping at epoch {epoch+1}\")\n            break\n    \n    tqdm.write(f\"Epoch [{epoch+1}/{EPOCHS}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n\n    # Apply learning rate scheduling\n    scheduler.step()\n\n    # Append the losses for this epoch\n    train_losses.append(avg_train_loss)\n    val_losses.append(avg_val_loss)\n\n# Create a DataFrame to store the losses\nloss_df = pd.DataFrame({'val_loss': val_losses, 'train_loss': train_losses})\n\n# Plot the losses\nplt.plot(loss_df.index + 1, loss_df['train_loss'], label='Train Loss')\nplt.plot(loss_df.index + 1, loss_df['val_loss'], label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Training and Validation Losses')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-17T20:15:21.786850Z","iopub.execute_input":"2024-04-17T20:15:21.787218Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/35 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb2e21d66e5e4c049894c800fccb9ad6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/883 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fce6404637d048b7b05ec96b1d388fbf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/295 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"baabe30c426347e7bcd873faf354acac"}},"metadata":{}},{"name":"stdout","text":"Epoch [1/35], Train Loss: 6.3684, Val Loss: 4.0115\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/883 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b691cd4f2fc41dd8a18226c7e148b8c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/295 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"103d2ca83de74ce0931ee411612bba7a"}},"metadata":{}},{"name":"stdout","text":"Epoch [2/35], Train Loss: 3.9612, Val Loss: 3.8838\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/883 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53e03c85c58141b0b6dc2e320c434990"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/295 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"738817b663354bf6b5aab81da75f3323"}},"metadata":{}},{"name":"stdout","text":"Epoch [3/35], Train Loss: 3.8655, Val Loss: 3.8017\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/883 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3c2378cc88b4c13baa2e4d2601c8ef5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/295 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ee9075779dd4a5d82f5303aebae8755"}},"metadata":{}},{"name":"stdout","text":"Epoch [4/35], Train Loss: 3.8328, Val Loss: 3.7564\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/883 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5461d1a4014a428a99f44436b7f9c9a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/295 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed70ee4839c94d90a619bd52fec50a85"}},"metadata":{}},{"name":"stdout","text":"Epoch [5/35], Train Loss: 3.7907, Val Loss: 3.7185\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/883 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b50ce099d274c0586e3e6a606d67809"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/295 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d03eb5e3b0f44066ac49c66a6b65f8f4"}},"metadata":{}},{"name":"stdout","text":"Epoch [6/35], Train Loss: 3.7803, Val Loss: 3.7055\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/883 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"639b82f48a784b3b8167101345d4eb1f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/295 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d3a0f7eec2a493c9822c6e7d0a46475"}},"metadata":{}},{"name":"stdout","text":"Epoch [7/35], Train Loss: 3.6879, Val Loss: 3.6882\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/883 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2aa9783adc7a4ce5887766db6e7eb069"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/295 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05e8ad07072243ef83049a78f86e6b2b"}},"metadata":{}},{"name":"stdout","text":"Epoch [8/35], Train Loss: 3.6817, Val Loss: 3.7375\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/883 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ffb6a62437014ff2862bcc12e9d8a176"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/295 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2cd5d41dc2d4c4d9358f23422891891"}},"metadata":{}},{"name":"stdout","text":"Epoch [9/35], Train Loss: 3.6794, Val Loss: 3.6792\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/883 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3665acdf41c44227ab7efaa799c4ca84"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/295 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c7eaa5f882c4b96ba55cdef3206f3dc"}},"metadata":{}},{"name":"stdout","text":"Epoch [10/35], Train Loss: 3.6769, Val Loss: 3.7013\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/883 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48eb22987c934c9c83f1535a9f9f231c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/295 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f16c986801f43f6bff793e0e2ad4127"}},"metadata":{}},{"name":"stdout","text":"Epoch [11/35], Train Loss: 3.6709, Val Loss: 3.6819\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/883 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"809e098162754883bb6cacf65ea7dfba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/295 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33553396284f4f85952955c8b49c7245"}},"metadata":{}},{"name":"stdout","text":"Epoch [12/35], Train Loss: 3.6684, Val Loss: 3.6744\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/883 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09940f6111b344f49e1778b526ed7779"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/295 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f67589f41395485fa2d46b433e58ddd1"}},"metadata":{}},{"name":"stdout","text":"Epoch [13/35], Train Loss: 3.6587, Val Loss: 3.6705\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/883 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55fdf045365642b8b72398a904ec597b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/295 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f57aaa4d47c4eddad2601281de17fff"}},"metadata":{}},{"name":"stdout","text":"Epoch [14/35], Train Loss: 3.6589, Val Loss: 3.6709\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/883 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc37ddd730c84880b6fca8b9301d71ec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/295 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97c4186edd8f410eba1cb19f174e5b65"}},"metadata":{}},{"name":"stdout","text":"Epoch [15/35], Train Loss: 3.6573, Val Loss: 3.6712\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/883 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72b425b1fa8a49929d1966e446c705ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/295 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"429a4d02836a406fb59ecfd3de4fa1be"}},"metadata":{}},{"name":"stdout","text":"Epoch [16/35], Train Loss: 3.6572, Val Loss: 3.6699\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/883 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d557084a630548dbaaf01308c58650a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/295 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23555b19e7394f29a188e56e0d70c71d"}},"metadata":{}},{"name":"stdout","text":"Epoch [17/35], Train Loss: 3.6561, Val Loss: 3.6711\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/883 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cafa0f1c56db49f9bdd3b63a3aa686ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/295 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"947d2db33808483e90a5686f22f7bd28"}},"metadata":{}},{"name":"stdout","text":"Epoch [18/35], Train Loss: 3.6569, Val Loss: 3.6743\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/883 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"228e746be5794f86b3d5c6cad182933e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/295 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"857009190b5f46008ddafe7938af9ee0"}},"metadata":{}},{"name":"stdout","text":"Epoch [19/35], Train Loss: 3.6563, Val Loss: 3.6693\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/883 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c65ad68eb424a8a8b170ce55eaf25f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/295 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"daa314e6b5264c5cbbe81307446710da"}},"metadata":{}},{"name":"stdout","text":"Epoch [20/35], Train Loss: 3.6569, Val Loss: 3.6691\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/883 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f33fdebba0d4c94b09d1c17a24ce64f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/295 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb677504236740beb36b64e56343ba24"}},"metadata":{}},{"name":"stdout","text":"Epoch [21/35], Train Loss: 3.6558, Val Loss: 3.6691\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/883 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c8d3faae27648ba840cb0d9ce127d28"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/295 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df198895d8cc4ba6894bb1e3ce5bdde4"}},"metadata":{}},{"name":"stdout","text":"Epoch [22/35], Train Loss: 3.6554, Val Loss: 3.6690\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/883 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1958317653eb43d69c82480c769d94e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/295 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de11fa30cc4b46689886f2f46284b512"}},"metadata":{}},{"name":"stdout","text":"Epoch [23/35], Train Loss: 3.6552, Val Loss: 3.6690\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/883 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29af4d90088c4c7997f944ab3314c487"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/295 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ee538ccd5b843578f2cf9c15fec39e3"}},"metadata":{}},{"name":"stdout","text":"Epoch [24/35], Train Loss: 3.6555, Val Loss: 3.6689\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/883 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f4aae9447a44f6188741f662223fb31"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/295 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"346074ff27bd45c2995dad0b2ab097a0"}},"metadata":{}},{"name":"stdout","text":"Epoch [25/35], Train Loss: 3.6543, Val Loss: 3.6689\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/883 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4edd8862322743d8b16017de88b50a99"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/295 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4649af1bbace4424b45c9858ae6df1be"}},"metadata":{}},{"name":"stdout","text":"Epoch [26/35], Train Loss: 3.6549, Val Loss: 3.6689\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/883 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"594ea107f8944bdfbba8f59673893753"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/295 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd908fd4297a431fa7d7875c163252c2"}},"metadata":{}},{"name":"stdout","text":"Epoch [27/35], Train Loss: 3.6545, Val Loss: 3.6689\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/883 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbd434958bf74a67a2859d2605193337"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/295 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4ee190d491e40619fcc51b368e61c5e"}},"metadata":{}},{"name":"stdout","text":"Epoch [28/35], Train Loss: 3.6558, Val Loss: 3.6689\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/883 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b062d7c6d4824fd0ba3c5c4d1a3a26c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/295 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"afbb736453144dbfa5c31efb2f87f57b"}},"metadata":{}},{"name":"stdout","text":"Epoch [29/35], Train Loss: 3.6550, Val Loss: 3.6689\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/883 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d43a9a793c6492faa2aecd0f62caaa6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/295 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aca33310b42948a89de154387839e090"}},"metadata":{}}]},{"cell_type":"markdown","source":"## Inference","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    model.eval()\n    predictions = model(test.values)\npredictions","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Hyper parameter tuning","metadata":{}},{"cell_type":"code","source":"def train_model(X_train_tensor, y_train_tensor, params):\n    \"\"\"\n    Train the FT-Transformer model with the given hyperparameters.\n    \n    Args:\n        X_train_tensor (torch.Tensor): Input training data tensor.\n        y_train_tensor (torch.Tensor): Target training data tensor.\n        params (dict): Hyperparameters for the model.\n        \n    Returns:\n        float: Average validation RMSE across folds.\n    \"\"\"\n    # Unpack the hyperparameters\n    input_dim = X_train_tensor.shape[1]\n    num_trees = params['num_trees']\n    depth = params['depth']\n    num_epochs = 35 \n    batch_size = params['batch_size']\n    early_stopping_patience = params['early_stopping_patience']\n    \n    # Set the device (GPU if available, else CPU)\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    # Create the FT-Transformer model\n    model = NODEModel(input_dim, num_trees, depth).to(device)\n    \n    # Define the loss function and optimizer\n    criterion = nn.MSELoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    \n    # Create KFold cross-validator\n    kf = KFold(n_splits=3, shuffle=True, random_state=42)\n    best_val_rmse_folds = []\n    \n    # Perform k-fold cross-validation\n    for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_tensor)):\n        print(f\"Fold [{fold+1}/3]\")\n\n        # Create train and validation datasets using the indices\n        train_dataset = torch.utils.data.TensorDataset(X_train_tensor[train_idx], y_train_tensor[train_idx])\n        val_dataset = torch.utils.data.TensorDataset(X_train_tensor[val_idx], y_train_tensor[val_idx])\n\n        # Create data loaders for train and validation datasets\n        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n        val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size)\n\n        # Initialize variables for early stopping\n        best_val_rmse = float('inf')  # Initialize best_val_rmse here\n        best_model_state = None\n        patience_counter = 0\n\n        # Training loop\n        for epoch in tqdm(range(num_epochs)):\n            model.train()\n            \n            # Iterate over the training batches\n            for batch_X, batch_y in train_loader:\n                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n                \n                # Forward pass\n                optimizer.zero_grad()\n                outputs = model(batch_X)\n                loss = criterion(outputs, batch_y)\n                \n                # Backward pass and optimization\n                loss.backward()\n                optimizer.step()\n            \n            model.eval()\n            val_predictions = []\n            val_targets = []\n            \n            # Iterate over the validation batches\n            with torch.no_grad():\n                for batch_X, batch_y in val_loader:\n                    batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n                    outputs = model(batch_X)\n                    val_predictions.append(outputs.squeeze().cpu().numpy())\n                    val_targets.append(batch_y.cpu().numpy())\n            \n            # Concatenate the validation predictions and targets\n            val_predictions = np.concatenate(val_predictions)\n            val_targets = np.concatenate(val_targets)\n            \n            # Calculate validation RMSE\n            val_rmse = np.sqrt(mean_squared_error(val_targets, val_predictions))\n            print(f\"Epoch [{epoch+1}/{num_epochs}], Validation RMSE: {val_rmse:.4f}\")\n            \n            # Check for early stopping\n            if val_rmse < best_val_rmse:\n                best_val_rmse = val_rmse\n                best_model_state = model.state_dict()\n                patience_counter = 0\n            else:\n                patience_counter += 1\n                if patience_counter >= early_stopping_patience:\n                    print(f\"Early stopping at epoch {epoch+1}\")\n                    break\n        \n        # Store the best validation RMSE for the current fold\n        best_val_rmse_folds.append(best_val_rmse)\n        \n        # Load the best model state for the current fold\n        model.load_state_dict(best_model_state)\n    \n    # Calculate the average validation RMSE across all folds\n    avg_val_rmse = np.mean(best_val_rmse_folds)\n    print(f\"Average Validation RMSE across folds: {avg_val_rmse:.4f}\")\n    \n    return avg_val_rmse\n\n# Define objective function for Optuna\ndef objective(trial):\n    \"\"\"\n    Objective function for hyperparameter optimization.\n    \n    Args:\n        trial (optuna.trial.Trial): Optuna trial object.\n        \n    Returns:\n        float: Average validation RMSE.\n    \"\"\"\n    # Define the hyperparameter search space\n    params = {\n        'num_trees': trial.suggest_int('num_trees', 50, 200),\n        'depth': trial.suggest_int('depth', 4, 8),\n        'batch_size': trial.suggest_int('batch_size', 16, 128),\n        'early_stopping_patience': 6\n    }\n    \n    # Train the model with the current hyperparameters\n    avg_val_rmse = train_model(X_train_tensor, y_train_tensor, params)\n    \n    return avg_val_rmse\n\n# Create an Optuna study\nstudy = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n\n# Optimize the hyperparameters\nstudy.optimize(objective, n_trials=100)\n\n# Print the best hyperparameters and validation RMSE\nprint(\"Best hyperparameters:\", study.best_params)\nprint(\"Best validation RMSE:\", study.best_value)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T19:04:36.738743Z","iopub.execute_input":"2024-04-17T19:04:36.739492Z","iopub.status.idle":"2024-04-17T19:35:33.497194Z","shell.execute_reply.started":"2024-04-17T19:04:36.739462Z","shell.execute_reply":"2024-04-17T19:35:33.495700Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"[I 2024-04-17 19:04:36,757] A new study created in memory with name: no-name-dbcb894c-1d75-4017-b744-5b0694c81583\n","output_type":"stream"},{"name":"stdout","text":"Fold [1/3]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/35 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"709e82aab98a474fa78c2613e624e799"}},"metadata":{}},{"name":"stdout","text":"Epoch [1/35], Validation RMSE: 2.4159\nEpoch [2/35], Validation RMSE: 2.2853\nEpoch [3/35], Validation RMSE: 2.1511\nEpoch [4/35], Validation RMSE: 2.0636\nEpoch [5/35], Validation RMSE: 2.0175\nEpoch [6/35], Validation RMSE: 2.0071\nEpoch [7/35], Validation RMSE: 1.9958\nEpoch [8/35], Validation RMSE: 1.9986\nEpoch [9/35], Validation RMSE: 1.9840\nEpoch [10/35], Validation RMSE: 1.9803\nEpoch [11/35], Validation RMSE: 1.9783\nEpoch [12/35], Validation RMSE: 1.9730\nEpoch [13/35], Validation RMSE: 1.9780\nEpoch [14/35], Validation RMSE: 1.9658\nEpoch [15/35], Validation RMSE: 1.9629\nEpoch [16/35], Validation RMSE: 1.9624\nEpoch [17/35], Validation RMSE: 1.9577\nEpoch [18/35], Validation RMSE: 1.9994\nEpoch [19/35], Validation RMSE: 1.9611\nEpoch [20/35], Validation RMSE: 1.9510\nEpoch [21/35], Validation RMSE: 1.9604\nEpoch [22/35], Validation RMSE: 1.9655\nEpoch [23/35], Validation RMSE: 1.9444\nEpoch [24/35], Validation RMSE: 1.9524\nEpoch [25/35], Validation RMSE: 1.9426\nEpoch [26/35], Validation RMSE: 1.9478\nEpoch [27/35], Validation RMSE: 1.9457\nEpoch [28/35], Validation RMSE: 1.9569\nEpoch [29/35], Validation RMSE: 1.9377\nEpoch [30/35], Validation RMSE: 1.9375\nEpoch [31/35], Validation RMSE: 1.9349\nEpoch [32/35], Validation RMSE: 1.9460\nEpoch [33/35], Validation RMSE: 1.9343\nEpoch [34/35], Validation RMSE: 1.9375\nEpoch [35/35], Validation RMSE: 1.9407\nFold [2/3]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/35 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00a4b5758e5640feb168348ed42a5eb7"}},"metadata":{}},{"name":"stdout","text":"Epoch [1/35], Validation RMSE: 1.8999\nEpoch [2/35], Validation RMSE: 1.8907\nEpoch [3/35], Validation RMSE: 1.8938\nEpoch [4/35], Validation RMSE: 1.9022\nEpoch [5/35], Validation RMSE: 1.8908\nEpoch [6/35], Validation RMSE: 1.8894\nEpoch [7/35], Validation RMSE: 1.8900\nEpoch [8/35], Validation RMSE: 1.8958\nEpoch [9/35], Validation RMSE: 1.8903\nEpoch [10/35], Validation RMSE: 1.8955\nEpoch [11/35], Validation RMSE: 1.9118\nEpoch [12/35], Validation RMSE: 1.8868\nEpoch [13/35], Validation RMSE: 1.8881\nEpoch [14/35], Validation RMSE: 1.8837\nEpoch [15/35], Validation RMSE: 1.8939\nEpoch [16/35], Validation RMSE: 1.8850\nEpoch [17/35], Validation RMSE: 1.8814\nEpoch [18/35], Validation RMSE: 1.8907\nEpoch [19/35], Validation RMSE: 1.9102\nEpoch [20/35], Validation RMSE: 1.8815\nEpoch [21/35], Validation RMSE: 1.8954\nEpoch [22/35], Validation RMSE: 1.8862\nEpoch [23/35], Validation RMSE: 1.8799\nEpoch [24/35], Validation RMSE: 1.8857\nEpoch [25/35], Validation RMSE: 1.8822\nEpoch [26/35], Validation RMSE: 1.8793\nEpoch [27/35], Validation RMSE: 1.8790\nEpoch [28/35], Validation RMSE: 1.9020\nEpoch [29/35], Validation RMSE: 1.8804\nEpoch [30/35], Validation RMSE: 1.8773\nEpoch [31/35], Validation RMSE: 1.8849\nEpoch [32/35], Validation RMSE: 1.8807\nEpoch [33/35], Validation RMSE: 1.8801\nEpoch [34/35], Validation RMSE: 1.8799\nEpoch [35/35], Validation RMSE: 1.8812\nFold [3/3]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/35 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb0ae2d753ee485f99299af14068a64d"}},"metadata":{}},{"name":"stdout","text":"Epoch [1/35], Validation RMSE: 1.8983\nEpoch [2/35], Validation RMSE: 1.9011\nEpoch [3/35], Validation RMSE: 1.8994\nEpoch [4/35], Validation RMSE: 1.8950\nEpoch [5/35], Validation RMSE: 1.8958\nEpoch [6/35], Validation RMSE: 1.9059\nEpoch [7/35], Validation RMSE: 1.9099\nEpoch [8/35], Validation RMSE: 1.8969\nEpoch [9/35], Validation RMSE: 1.9019\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-04-17 19:32:02,820] Trial 0 finished with value: 1.9021824598312378 and parameters: {'num_trees': 106, 'depth': 8, 'batch_size': 98}. Best is trial 0 with value: 1.9021824598312378.\n","output_type":"stream"},{"name":"stdout","text":"Epoch [10/35], Validation RMSE: 1.8955\nEarly stopping at epoch 10\nAverage Validation RMSE across folds: 1.9022\nFold [1/3]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/35 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c184c9627a14c969680809e5637bd1e"}},"metadata":{}},{"name":"stdout","text":"Epoch [1/35], Validation RMSE: 2.4794\nEpoch [2/35], Validation RMSE: 2.3884\n","output_type":"stream"},{"name":"stderr","text":"[W 2024-04-17 19:35:32,524] Trial 1 failed with parameters: {'num_trees': 140, 'depth': 4, 'batch_size': 33} because of the following error: KeyboardInterrupt().\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n    value_or_values = func(trial)\n  File \"/tmp/ipykernel_34/373353929.py\", line 132, in objective\n    avg_val_rmse = train_model(X_train_tensor, y_train_tensor, params)\n  File \"/tmp/ipykernel_34/373353929.py\", line 67, in train_model\n    optimizer.step()\n  File \"/opt/conda/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 373, in wrapper\n    out = func(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 76, in _use_grad\n    ret = func(self, *args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/optim/adam.py\", line 163, in step\n    adam(\n  File \"/opt/conda/lib/python3.10/site-packages/torch/optim/adam.py\", line 311, in adam\n    func(params,\n  File \"/opt/conda/lib/python3.10/site-packages/torch/optim/adam.py\", line 569, in _multi_tensor_adam\n    torch._foreach_addcdiv_(device_params, device_exp_avgs, exp_avg_sq_sqrt, step_size)\nKeyboardInterrupt\n[W 2024-04-17 19:35:32,534] Trial 1 failed with value None.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[6], line 140\u001b[0m\n\u001b[1;32m    137\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m, sampler\u001b[38;5;241m=\u001b[39moptuna\u001b[38;5;241m.\u001b[39msamplers\u001b[38;5;241m.\u001b[39mTPESampler(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m))\n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m# Optimize the hyperparameters\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# Print the best hyperparameters and validation RMSE\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest hyperparameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, study\u001b[38;5;241m.\u001b[39mbest_params)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/optuna/study/_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 62\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/optuna/study/_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/optuna/study/_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    246\u001b[0m ):\n\u001b[0;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/optuna/study/_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n","Cell \u001b[0;32mIn[6], line 132\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m    124\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_trees\u001b[39m\u001b[38;5;124m'\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_int(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_trees\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m200\u001b[39m),\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdepth\u001b[39m\u001b[38;5;124m'\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_int(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdepth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m8\u001b[39m),\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_int(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m128\u001b[39m),\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mearly_stopping_patience\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m6\u001b[39m\n\u001b[1;32m    129\u001b[0m }\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# Train the model with the current hyperparameters\u001b[39;00m\n\u001b[0;32m--> 132\u001b[0m avg_val_rmse \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m avg_val_rmse\n","Cell \u001b[0;32mIn[6], line 67\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(X_train_tensor, y_train_tensor, params)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# Backward pass and optimization\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 67\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     70\u001b[0m val_predictions \u001b[38;5;241m=\u001b[39m []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    370\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m             )\n\u001b[0;32m--> 373\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/adam.py:163\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    152\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    155\u001b[0m         group,\n\u001b[1;32m    156\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    160\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    161\u001b[0m         state_steps)\n\u001b[0;32m--> 163\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/adam.py:311\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 311\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/adam.py:569\u001b[0m, in \u001b[0;36m_multi_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    567\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_div_(exp_avg_sq_sqrt, bias_correction2_sqrt)\n\u001b[1;32m    568\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_add_(exp_avg_sq_sqrt, eps)\n\u001b[0;32m--> 569\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_foreach_addcdiv_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_exp_avgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp_avg_sq_sqrt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep_size\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]}]}