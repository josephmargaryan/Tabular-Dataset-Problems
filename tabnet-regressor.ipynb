{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":72489,"databundleVersionId":8096274,"sourceType":"competition"},{"sourceId":8113848,"sourceType":"datasetVersion","datasetId":4793413}],"dockerImageVersionId":30684,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm, trange\nimport optuna\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import StepLR\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import MinMaxScaler, LabelEncoder\nfrom sklearn.model_selection import KFold\n\nimport optuna\nfrom optuna.samplers import TPESampler","metadata":{"execution":{"iopub.status.busy":"2024-04-17T12:43:29.570198Z","iopub.execute_input":"2024-04-17T12:43:29.571000Z","iopub.status.idle":"2024-04-17T12:43:34.702178Z","shell.execute_reply.started":"2024-04-17T12:43:29.570953Z","shell.execute_reply":"2024-04-17T12:43:34.701382Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"%%capture\n!pip install pytorch_tabnet","metadata":{"execution":{"iopub.status.busy":"2024-04-17T12:43:59.594029Z","iopub.execute_input":"2024-04-17T12:43:59.595055Z","iopub.status.idle":"2024-04-17T12:44:13.637170Z","shell.execute_reply.started":"2024-04-17T12:43:59.595006Z","shell.execute_reply":"2024-04-17T12:44:13.635874Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from pytorch_tabnet.tab_model import TabNetRegressor","metadata":{"execution":{"iopub.status.busy":"2024-04-17T12:44:28.270323Z","iopub.execute_input":"2024-04-17T12:44:28.271325Z","iopub.status.idle":"2024-04-17T12:44:28.291648Z","shell.execute_reply.started":"2024-04-17T12:44:28.271282Z","shell.execute_reply":"2024-04-17T12:44:28.290641Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Read data","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/playground-series-s4e4/train.csv')\ntest = pd.read_csv('/kaggle/input/playground-series-s4e4/test.csv')\ntrain.drop(columns=['id'], axis=1, inplace=True)\ntest.drop(columns=['id'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T12:44:31.724345Z","iopub.execute_input":"2024-04-17T12:44:31.725326Z","iopub.status.idle":"2024-04-17T12:44:32.061444Z","shell.execute_reply.started":"2024-04-17T12:44:31.725286Z","shell.execute_reply":"2024-04-17T12:44:32.060558Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Preprocess data","metadata":{}},{"cell_type":"code","source":"encoder = LabelEncoder()\nscaler = MinMaxScaler()\n\ntrain['Sex'] = encoder.fit_transform(train['Sex'])\ntest['Sex'] = encoder.transform(test['Sex'])\n\ncat_cols = ['Sex']\ntarget = 'Rings'\ncontinuous_cols = [col for col in train.columns if col not in cat_cols + [target]]\n\ntrain[continuous_cols] = scaler.fit_transform(train[continuous_cols])\ntest[continuous_cols] = scaler.transform(test[continuous_cols])\n\nX = train.drop(columns=['Rings'], axis=1).values\ny = train['Rings'].values.reshape(-1, 1)\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.27, random_state=24)\nX_train_tensor = torch.tensor(X_train, dtype=torch.float32)\nX_val_tensor = torch.tensor(X_val, dtype=torch.float32)\ny_train_tensor = torch.tensor(y_train, dtype=torch.float32)\ny_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n\n# Create TensorDataset instances for training and validation\ntrain_dataset = TensorDataset(X_train_tensor, y_train_tensor)\nval_dataset = TensorDataset(X_val_tensor, y_val_tensor)\nbatch_size = 97\n# Create DataLoader instances for training and validation\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T12:44:35.447228Z","iopub.execute_input":"2024-04-17T12:44:35.447606Z","iopub.status.idle":"2024-04-17T12:44:35.551885Z","shell.execute_reply.started":"2024-04-17T12:44:35.447576Z","shell.execute_reply":"2024-04-17T12:44:35.551068Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Define network","metadata":{}},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {'n_d': 13, 'n_a': 16, \n          'n_steps': 7, \n          'gamma': 1.7530486543675008, \n          'n_independent': 2, 'n_shared': 1, \n          'momentum': 0.18408553079911108, \n          'clip_value': 0.8420021070703481, \n          'lambda_sparse': 0.0005891219059313855}\nmodel = TabNetRegressor(**params)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T12:45:29.681477Z","iopub.execute_input":"2024-04-17T12:45:29.681836Z","iopub.status.idle":"2024-04-17T12:45:29.688476Z","shell.execute_reply.started":"2024-04-17T12:45:29.681807Z","shell.execute_reply":"2024-04-17T12:45:29.687351Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Define training loop","metadata":{}},{"cell_type":"code","source":"model.fit(\n    X_train, y_train,\n    eval_set=[(X_val, y_val)],\n    patience=3,  # Adjust patience as needed\n    max_epochs=20,  # Set maximum number of epochs\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T12:51:45.830997Z","iopub.execute_input":"2024-04-17T12:51:45.831424Z","iopub.status.idle":"2024-04-17T12:53:34.880136Z","shell.execute_reply.started":"2024-04-17T12:51:45.831394Z","shell.execute_reply":"2024-04-17T12:53:34.879281Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"epoch 0  | loss: 8.64175 | val_0_mse: 8.6619  |  0:00:05s\nepoch 1  | loss: 4.5031  | val_0_mse: 8.35007 |  0:00:11s\nepoch 2  | loss: 4.17191 | val_0_mse: 6.37626 |  0:00:17s\nepoch 3  | loss: 4.04824 | val_0_mse: 6.29605 |  0:00:23s\nepoch 4  | loss: 3.90284 | val_0_mse: 5.26967 |  0:00:29s\nepoch 5  | loss: 3.87069 | val_0_mse: 5.03647 |  0:00:35s\nepoch 6  | loss: 3.80008 | val_0_mse: 4.07813 |  0:00:41s\nepoch 7  | loss: 3.79443 | val_0_mse: 4.26017 |  0:00:47s\nepoch 8  | loss: 3.73569 | val_0_mse: 3.84917 |  0:00:53s\nepoch 9  | loss: 3.79702 | val_0_mse: 3.68383 |  0:00:58s\nepoch 10 | loss: 3.78948 | val_0_mse: 3.68223 |  0:01:04s\nepoch 11 | loss: 3.71858 | val_0_mse: 3.59184 |  0:01:10s\nepoch 12 | loss: 3.69564 | val_0_mse: 3.63725 |  0:01:16s\nepoch 13 | loss: 3.69753 | val_0_mse: 3.68556 |  0:01:22s\nepoch 14 | loss: 3.66446 | val_0_mse: 3.4993  |  0:01:28s\nepoch 15 | loss: 3.68347 | val_0_mse: 3.64818 |  0:01:34s\nepoch 16 | loss: 3.68848 | val_0_mse: 3.64977 |  0:01:40s\nepoch 17 | loss: 3.68257 | val_0_mse: 3.63968 |  0:01:46s\n\nEarly stopping occurred at epoch 17 with best_epoch = 14 and best_val_0_mse = 3.4993\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n  warnings.warn(wrn_msg)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Inference","metadata":{}},{"cell_type":"code","source":"# Inference\n\n# Perform inference on the test data\ntest_preds = model.predict(test.values)\n\n# Assuming you want to convert the predictions to a NumPy array\ntest_preds_np = test_preds\ntest_preds_np","metadata":{"execution":{"iopub.status.busy":"2024-04-17T12:55:43.284766Z","iopub.execute_input":"2024-04-17T12:55:43.285279Z","iopub.status.idle":"2024-04-17T12:55:45.412604Z","shell.execute_reply.started":"2024-04-17T12:55:43.285246Z","shell.execute_reply":"2024-04-17T12:55:45.411623Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"array([[ 9.932756],\n       [ 9.775032],\n       [10.297734],\n       ...,\n       [12.535048],\n       [13.190065],\n       [ 7.954035]], dtype=float32)"},"metadata":{}}]},{"cell_type":"markdown","source":"## Hyperparameter tune ","metadata":{}},{"cell_type":"code","source":"def train_model(X_train_tensor, y_train_tensor, params):\n    \"\"\"\n    Train the TabNet model with the given hyperparameters.\n    \n    Args:\n        X_train_tensor (torch.Tensor): Input features tensor.\n        y_train_tensor (torch.Tensor): Target tensor.\n        params (dict): Hyperparameters for the model.\n        \n    Returns:\n        float: Average validation RMSE across folds.\n    \"\"\"\n    # Unpack the hyperparameters\n    input_dim = X_train_tensor.shape[1]\n    n_d = params['n_d']\n    n_a = params['n_a']\n    n_steps = params['n_steps']\n    gamma = params['gamma']\n    cat_idxs = []\n    cat_dims = []\n    cat_emb_dim = []\n    n_independent = params['n_independent']\n    n_shared = params['n_shared']\n    momentum = params['momentum']\n    clip_value = params['clip_value']\n    lambda_sparse = params['lambda_sparse']\n    num_epochs = params['num_epochs']\n    batch_size = params['batch_size']\n    patience = params['patience']\n    virtual_batch_size = params['virtual_batch_size']\n    \n    # Create the TabNet model\n    model = TabNetRegressor(\n        input_dim=input_dim,\n        output_dim=1,\n        n_d=n_d,\n        n_a=n_a,\n        n_steps=n_steps,\n        gamma=gamma,\n        cat_idxs=cat_idxs,\n        cat_dims=cat_dims,\n        cat_emb_dim=cat_emb_dim,\n        n_independent=n_independent,\n        n_shared=n_shared,\n        momentum=momentum,\n        clip_value=clip_value,\n        lambda_sparse=lambda_sparse,\n        device_name='cuda'\n    )\n    \n    # Create KFold cross-validator\n    kf = KFold(n_splits=3, shuffle=True, random_state=42)\n    best_val_rmse_folds = []\n    \n    # Perform k-fold cross-validation\n    for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_tensor)):\n        print(f\"Fold [{fold+1}/3]\")\n        \n        # Train the model\n        model.fit(\n            X_train=X_train_tensor[train_idx].numpy(),  # Convert to NumPy array\n            y_train=y_train_tensor[train_idx].numpy(),  # Convert to NumPy array\n            eval_set=[(X_train_tensor[val_idx].numpy(), y_train_tensor[val_idx].numpy())],  # Convert to NumPy array\n            max_epochs=num_epochs,\n            patience=patience,\n            batch_size=batch_size,\n            virtual_batch_size=virtual_batch_size,\n            eval_metric=['rmse']\n        )\n        \n        # Make predictions on the validation set\n        val_predictions = model.predict(X_train_tensor[val_idx].numpy())  # Convert to NumPy array\n        \n        # Calculate validation RMSE\n        val_rmse = np.sqrt(mean_squared_error(y_train_tensor[val_idx].numpy(), val_predictions.squeeze()))  # Convert to NumPy array\n        print(f\"Validation RMSE: {val_rmse:.4f}\")\n        \n        # Store the validation RMSE for the current fold\n        best_val_rmse_folds.append(val_rmse)\n    \n    # Calculate the average validation RMSE across all folds\n    avg_val_rmse = np.mean(best_val_rmse_folds)\n    print(f\"Average Validation RMSE across folds: {avg_val_rmse:.4f}\")\n    \n    return avg_val_rmse\n\ndef objective(trial):\n    \"\"\"\n    Objective function for hyperparameter optimization.\n    \n    Args:\n        trial (optuna.trial.Trial): Optuna trial object.\n        \n    Returns:\n        float: Average validation RMSE.\n    \"\"\"\n    params = {\n        'n_d': trial.suggest_int('n_d', 8, 64),\n        'n_a': trial.suggest_int('n_a', 8, 64),\n        'n_steps': trial.suggest_int('n_steps', 3, 10),\n        'gamma': trial.suggest_float('gamma', 1.0, 2.0),\n        'n_independent': trial.suggest_int('n_independent', 1, 5),\n        'n_shared': trial.suggest_int('n_shared', 1, 5),\n        'momentum': trial.suggest_float('momentum', 0.01, 0.4),\n        'clip_value': trial.suggest_float('clip_value', 0.01, 2.0),\n        'lambda_sparse': trial.suggest_float('lambda_sparse', 0.0001, 0.01, log=True),\n        'num_epochs': 200,\n        'batch_size': trial.suggest_int('batch_size', 16, 1024),\n        'patience': 10,\n        'virtual_batch_size': trial.suggest_int('virtual_batch_size', 16, 128)\n    }\n    \n    avg_val_rmse = train_model(X_train_tensor, y_train_tensor, params)  # Pass X_train_tensor and y_train_tensor\n    return avg_val_rmse\n\n# Create an Optuna study\nstudy = optuna.create_study(direction='minimize', sampler=TPESampler(multivariate=True))\n\n# Optimize the hyperparameters\nstudy.optimize(objective, timeout=3600 * 10)\n\n# Print the best hyperparameters and validation RMSE\nprint(\"Best hyperparameters:\", study.best_params)\nprint(\"Best validation RMSE:\", study.best_value)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T12:08:26.403649Z","iopub.execute_input":"2024-04-17T12:08:26.404135Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/optuna/samplers/_tpe/sampler.py:319: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.\n  warnings.warn(\n[I 2024-04-17 12:08:26,419] A new study created in memory with name: no-name-7dc7740d-bc9e-46cc-8f20-4b7261a967bf\n/opt/conda/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n  warnings.warn(f\"Device used : {self.device}\")\n","output_type":"stream"},{"name":"stdout","text":"Fold [1/3]\nepoch 0  | loss: 5.99872 | val_0_rmse: 2.418560028076172|  0:00:21s\nepoch 1  | loss: 4.46499 | val_0_rmse: 1.9803099632263184|  0:00:42s\nepoch 2  | loss: 4.30144 | val_0_rmse: 2.0053000450134277|  0:01:03s\nepoch 3  | loss: 4.12455 | val_0_rmse: 1.9707200527191162|  0:01:24s\nepoch 4  | loss: 4.17529 | val_0_rmse: 1.938920021057129|  0:01:45s\nepoch 5  | loss: 4.07522 | val_0_rmse: 1.9376399517059326|  0:02:06s\nepoch 6  | loss: 4.04532 | val_0_rmse: 1.9462300539016724|  0:02:27s\nepoch 7  | loss: 4.0765  | val_0_rmse: 1.9309200048446655|  0:02:48s\nepoch 8  | loss: 4.06111 | val_0_rmse: 1.989150047302246|  0:03:09s\nepoch 9  | loss: 3.98008 | val_0_rmse: 1.9353400468826294|  0:03:30s\nepoch 10 | loss: 4.02081 | val_0_rmse: 2.0060300827026367|  0:03:51s\nepoch 11 | loss: 3.98848 | val_0_rmse: 1.9197800159454346|  0:04:12s\nepoch 12 | loss: 3.96786 | val_0_rmse: 1.9210200309753418|  0:04:33s\nepoch 13 | loss: 3.97463 | val_0_rmse: 1.9080100059509277|  0:04:54s\nepoch 14 | loss: 4.00102 | val_0_rmse: 1.9302200078964233|  0:05:16s\nepoch 15 | loss: 3.89832 | val_0_rmse: 1.952929973602295|  0:05:37s\nepoch 16 | loss: 3.90952 | val_0_rmse: 1.936710000038147|  0:05:58s\nepoch 17 | loss: 3.89296 | val_0_rmse: 1.8918499946594238|  0:06:19s\nepoch 18 | loss: 3.95796 | val_0_rmse: 1.919450044631958|  0:06:40s\nepoch 19 | loss: 3.92241 | val_0_rmse: 1.8968600034713745|  0:07:01s\nepoch 20 | loss: 3.90321 | val_0_rmse: 1.9757399559020996|  0:07:22s\nepoch 21 | loss: 3.9157  | val_0_rmse: 1.9271999597549438|  0:07:43s\nepoch 22 | loss: 3.88834 | val_0_rmse: 1.8955899477005005|  0:08:05s\nepoch 23 | loss: 3.83869 | val_0_rmse: 1.8897099494934082|  0:08:26s\nepoch 24 | loss: 3.8675  | val_0_rmse: 1.9017000198364258|  0:08:48s\nepoch 25 | loss: 3.84888 | val_0_rmse: 1.9313000440597534|  0:09:11s\nepoch 26 | loss: 3.87377 | val_0_rmse: 1.9481600522994995|  0:09:33s\nepoch 27 | loss: 3.86012 | val_0_rmse: 1.8964600563049316|  0:09:54s\nepoch 28 | loss: 3.87214 | val_0_rmse: 1.9172600507736206|  0:10:16s\nepoch 29 | loss: 3.92053 | val_0_rmse: 1.9126700162887573|  0:10:38s\nepoch 30 | loss: 3.85271 | val_0_rmse: 1.9231499433517456|  0:10:59s\nepoch 31 | loss: 3.8373  | val_0_rmse: 2.0027201175689697|  0:11:21s\nepoch 32 | loss: 3.85473 | val_0_rmse: 1.9166899919509888|  0:11:44s\nepoch 33 | loss: 3.89068 | val_0_rmse: 1.9011600017547607|  0:12:06s\n\nEarly stopping occurred at epoch 33 with best_epoch = 23 and best_val_0_rmse = 1.8897099494934082\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n  warnings.warn(wrn_msg)\n","output_type":"stream"},{"name":"stdout","text":"Validation RMSE: 1.8897\nFold [2/3]\nepoch 0  | loss: 5.90405 | val_0_rmse: 2.2973899841308594|  0:00:22s\nepoch 1  | loss: 4.44973 | val_0_rmse: 2.0359199047088623|  0:00:44s\nepoch 5  | loss: 4.14287 | val_0_rmse: 1.9529600143432617|  0:02:12s\nepoch 6  | loss: 4.14098 | val_0_rmse: 2.0566699504852295|  0:02:33s\nepoch 7  | loss: 4.21602 | val_0_rmse: 2.0975399017333984|  0:02:55s\nepoch 8  | loss: 4.1228  | val_0_rmse: 1.9693700075149536|  0:03:16s\nepoch 9  | loss: 4.07529 | val_0_rmse: 1.9599599838256836|  0:03:38s\nepoch 10 | loss: 4.09453 | val_0_rmse: 1.9906100034713745|  0:03:59s\nepoch 11 | loss: 4.06394 | val_0_rmse: 1.9482899904251099|  0:04:20s\nepoch 12 | loss: 4.02315 | val_0_rmse: 1.9691400527954102|  0:04:42s\nepoch 13 | loss: 4.05814 | val_0_rmse: 2.018620014190674|  0:05:03s\nepoch 14 | loss: 4.08172 | val_0_rmse: 2.148710012435913|  0:05:25s\nepoch 15 | loss: 3.99589 | val_0_rmse: 1.9460500478744507|  0:05:47s\nepoch 16 | loss: 3.979   | val_0_rmse: 1.9655799865722656|  0:06:09s\nepoch 17 | loss: 3.95957 | val_0_rmse: 1.9932700395584106|  0:06:31s\nepoch 18 | loss: 3.91885 | val_0_rmse: 1.967479944229126|  0:06:53s\nepoch 19 | loss: 3.92324 | val_0_rmse: 1.9254599809646606|  0:07:15s\nepoch 20 | loss: 3.91038 | val_0_rmse: 2.100860118865967|  0:07:37s\nepoch 21 | loss: 3.90746 | val_0_rmse: 1.963379979133606|  0:07:59s\nepoch 22 | loss: 3.87925 | val_0_rmse: 1.9234000444412231|  0:08:21s\nepoch 23 | loss: 3.83936 | val_0_rmse: 1.940209984779358|  0:08:43s\nepoch 24 | loss: 3.8849  | val_0_rmse: 1.923509955406189|  0:09:05s\nepoch 25 | loss: 3.98428 | val_0_rmse: 1.927940011024475|  0:09:27s\nepoch 26 | loss: 3.90899 | val_0_rmse: 1.9824899435043335|  0:09:49s\nepoch 27 | loss: 3.91278 | val_0_rmse: 1.931920051574707|  0:10:11s\nepoch 28 | loss: 3.86647 | val_0_rmse: 1.9261000156402588|  0:10:33s\nepoch 29 | loss: 3.82738 | val_0_rmse: 1.9663599729537964|  0:10:55s\nepoch 30 | loss: 3.85101 | val_0_rmse: 1.9265999794006348|  0:11:17s\nepoch 31 | loss: 3.86889 | val_0_rmse: 1.9502500295639038|  0:11:39s\nepoch 32 | loss: 3.81338 | val_0_rmse: 1.9601500034332275|  0:12:01s\n\nEarly stopping occurred at epoch 32 with best_epoch = 22 and best_val_0_rmse = 1.9234000444412231\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n  warnings.warn(wrn_msg)\n","output_type":"stream"},{"name":"stdout","text":"Validation RMSE: 1.9234\nFold [3/3]\nepoch 0  | loss: 5.86462 | val_0_rmse: 2.5415499210357666|  0:00:22s\nepoch 1  | loss: 4.36388 | val_0_rmse: 2.001460075378418|  0:00:44s\nepoch 2  | loss: 4.26707 | val_0_rmse: 2.0100200176239014|  0:01:06s\nepoch 3  | loss: 4.15779 | val_0_rmse: 2.0599000453948975|  0:01:28s\nepoch 4  | loss: 4.12893 | val_0_rmse: 1.9616400003433228|  0:01:49s\nepoch 5  | loss: 4.16252 | val_0_rmse: 1.9894399642944336|  0:02:10s\nepoch 6  | loss: 4.11857 | val_0_rmse: 1.9378999471664429|  0:02:31s\nepoch 7  | loss: 4.03833 | val_0_rmse: 1.9389699697494507|  0:02:53s\nepoch 8  | loss: 3.98361 | val_0_rmse: 2.004319906234741|  0:03:14s\nepoch 9  | loss: 3.99602 | val_0_rmse: 1.9583499431610107|  0:03:35s\nepoch 10 | loss: 3.95483 | val_0_rmse: 1.9196300506591797|  0:03:57s\nepoch 11 | loss: 3.94651 | val_0_rmse: 1.9544800519943237|  0:04:18s\nepoch 12 | loss: 3.93076 | val_0_rmse: 1.9359099864959717|  0:04:40s\nepoch 13 | loss: 3.94538 | val_0_rmse: 1.9246900081634521|  0:05:01s\nepoch 14 | loss: 3.9067  | val_0_rmse: 1.9345699548721313|  0:05:23s\nepoch 15 | loss: 3.89612 | val_0_rmse: 1.9317400455474854|  0:05:44s\nepoch 16 | loss: 3.88002 | val_0_rmse: 2.094589948654175|  0:06:05s\nepoch 17 | loss: 3.87031 | val_0_rmse: 1.9510200023651123|  0:06:27s\nepoch 18 | loss: 3.8438  | val_0_rmse: 1.922760009765625|  0:06:49s\nepoch 19 | loss: 3.82269 | val_0_rmse: 1.9267699718475342|  0:07:10s\nepoch 20 | loss: 3.80725 | val_0_rmse: 2.096359968185425|  0:07:32s\n\nEarly stopping occurred at epoch 20 with best_epoch = 10 and best_val_0_rmse = 1.9196300506591797\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n  warnings.warn(wrn_msg)\n[I 2024-04-17 12:40:48,092] Trial 0 finished with value: 1.9109134674072266 and parameters: {'n_d': 13, 'n_a': 16, 'n_steps': 7, 'gamma': 1.7530486543675008, 'n_independent': 2, 'n_shared': 1, 'momentum': 0.18408553079911108, 'clip_value': 0.8420021070703481, 'lambda_sparse': 0.0005891219059313855, 'batch_size': 97, 'virtual_batch_size': 95}. Best is trial 0 with value: 1.9109134674072266.\n","output_type":"stream"},{"name":"stdout","text":"Validation RMSE: 1.9196\nAverage Validation RMSE across folds: 1.9109\nFold [1/3]\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n  warnings.warn(f\"Device used : {self.device}\")\n","output_type":"stream"},{"name":"stdout","text":"epoch 0  | loss: 9.23799 | val_0_rmse: 2.8239400386810303|  0:00:29s\nepoch 1  | loss: 4.82595 | val_0_rmse: 2.5552499294281006|  0:00:59s\nepoch 2  | loss: 4.61314 | val_0_rmse: 2.2804598808288574|  0:01:30s\nepoch 3  | loss: 4.35507 | val_0_rmse: 2.058799982070923|  0:02:00s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Hyperparameter search space is too long but the best results obtained were:\n{'num_heads': 7, 'hidden_dim': 122, 'num_layers': 4, 'dropout': 0.3672614749403933, 'batch_size': 85, 'learning_rate': 0.0012365343304592232}. Best is trial 1 with value: 1.9047857522964478.","metadata":{}}]}